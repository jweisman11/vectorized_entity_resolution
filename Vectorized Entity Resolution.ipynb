{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Entity Resolution: An Illustrative Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this excercise, we leverage a dataset of song information to see if we successfully resolve the number of entities into a true list of unique songs.  This dataset has already been resolved and the unique id for the true record is the column referred to as \"CID.\"  You can find the entire data dictionary below (listed by column). Source: University of Leipzig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Package Importation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below, we will only be using packages that are part of the Anaconda Python suite.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_kernels\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-processing required for this excercise is extremely straightforward.  In the first  and second cell, we import the dataframe and combine all of the identifying information (e.g. the song title and artist) into one cell.  From that point on, we will only use that column (called \"all\") and the cluster ID column to compare the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'Albums.csv')\n",
    "data.head()\n",
    "#IF YOUR COMPUTER CANNOT RUN THE BELOW CODE BECAUSE OF A MEMORY ERROR, UNCOMMENT THE LINE BELOW\n",
    "data = data[data['CID']>=500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is critical to format each cell as a string before concatenating them.\n",
    "data['all'] = data['title'].astype(str) + data['length'].astype(str) + data['artist'].astype(str) + data['album'].astype(str) + data['language'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>length</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, length, artist, album, year, language]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['CID']==6][['title', 'length', 'artist', 'album', 'year', 'language']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most important stage of the entity resolution process as the speed and efficiency of this step is what makes the entire process so useful.\n",
    "\n",
    "In the cell immediately below, we first instantiate a vectorizer with a term-frequency-inverse-document-frequency (TFIDF) normalizer.  TFIDF will count the attributes (in this case combinations of characters) in each cell and develop a score of that for each one of those attributes that weighes rarer combinations of characters more than more common combinations.  For instance the character combination \"xyz\" will be wieghed more than the character combination \"the\".  For information on the TFIDF algorythim, please see here: .\n",
    "\n",
    "The other important parameter of the vectorizer is the n_gram range, i.e. range of character combinations we select. In this case, we select 4 which means we will select character combinations of between 1 and 4 characters long.\n",
    "\n",
    "After instantiating the vectorizer, we then fit the vectorizer to the \"all\" column and then transform a matrix that scores the entire dataset on those 1-4 combinations of characters on the TFIDF alogrythim.  From this process we yield a extremely large matrix that has the length of the number of records in the dataset and width of the number of all combinations of 1-4 characters in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the vector with the aforementioned parameteres\n",
    "vect = TfidfVectorizer(analyzer='char', ngram_range=(1,4))\n",
    "#Fit the vector and transform it into a scored matrix\n",
    "matrix = vect.fit_transform(data['all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell, we compute a similarity score of the matrix using the cosine similarity function.  Cosine similarity is a measure of euclidean distance.  For more infomation about the cosine similarity function, please go here: .\n",
    "\n",
    "From that function, we obtain a matrix that score each record on its similarity with every other record.  Output of the cosine similarity function has the dimensions of NxN  where N is the total number of records.  On the diagonals of the matrix is score of the records similarity with itself.  We zero out the diagonal scores so that we can find matches based off of a score threshold later in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.26 GiB for an array with shape (337750876,) and data type int32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-cee4e44d498d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Compute the cosine similarity matrix. You must produce a sparse output in order save memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcos_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#Zero out diagonals of the cosine similarity matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1173\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0m\u001b[0;32m   1176\u001b[0m                         dense_output=dense_output)\n\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    562\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    563\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 564\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    514\u001b[0m                                     maxval=nnz)\n\u001b[0;32m    515\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.26 GiB for an array with shape (337750876,) and data type int32"
     ]
    }
   ],
   "source": [
    "#Compute the cosine similarity matrix. You must produce a sparse output in order save memory\n",
    "cos_sim = cosine_similarity(matrix, dense_output=False)\n",
    "#Zero out diagonals of the cosine similarity matrix\n",
    "cos_sim.setdiag(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all of the information that we need to resolve the song names in this dataset.  From the dataset documentation, we know that there are around 9000 duplicate names so we should determine the minimum cosine similarity score by looking at the portion of true duplicate records that we identify and the false positives we find.  \n",
    "\n",
    "First however, let's take a look what happens when we set a filter parameter of .95.  In this case, we only find 250 matches (keep in mind that we there is a low chance of duplicated matches).  Using the argwhere function, we find the index values for the record matches and put that list into a dataframe (for ease of analyis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter matches to the indices where the score value is higher than .95\n",
    "matches = np.argwhere(cos_sim>.95)\n",
    "#Format into a dataframe for ease of use.\n",
    "match_df= pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TID                                                       306\n",
       "CID                                                       162\n",
       "CTID                                                        1\n",
       "SourceID                                                    5\n",
       "id                                                   16288675\n",
       "number                                                     E4\n",
       "title               A Wand'ring Minstrel I, From \"The Mikado\"\n",
       "length                                                 261000\n",
       "artist              Sir William Gilbert & Sir Arthur Sullivan\n",
       "album                         Golden Sounds From the Classics\n",
       "year                                                      NaN\n",
       "language                                              English\n",
       "all         A Wand'ring Minstrel I, From \"The Mikado\"26100...\n",
       "Name: 305, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's look at an example of a match (record 1)\n",
    "data.iloc[305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TID                                                     15921\n",
       "CID                                                       162\n",
       "CTID                                                        3\n",
       "SourceID                                                    2\n",
       "id                                            MBox44023429-HH\n",
       "number                                                     E4\n",
       "title       Sir William Gilbert & Sir Arthur Sullivan - A ...\n",
       "length                                                    261\n",
       "artist                                                    NaN\n",
       "album                         Golden Sounds From the Classics\n",
       "year                                                      NaN\n",
       "language                                              English\n",
       "all         Sir William Gilbert & Sir Arthur Sullivan - A ...\n",
       "Name: 15920, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here's the record match\n",
    "data.iloc[15920]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analysis of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an idea what a match looks like, how do we determine where we set the threshold for the cosine similarity function?  One way is to look at the tradeoff between true and false positives at varying levels of similarity.  The below cell compiles the number of correctly identified duplicate songs and incorrectly indentified songs at similaritys scores between .4 and 1 while filtering out duplicate matches (see code below).  This information is then compiled in a dataframe that we will analyze in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame()\n",
    "for i in range(40,100,2):\n",
    "    #Iterate through several threshold scores.\n",
    "    threshold_val = i/100\n",
    "    matches = np.argwhere(cos_sim>threshold_val)\n",
    "    \n",
    "    match_count = 0\n",
    "    error_count= 0\n",
    "    errors_found=[]\n",
    "    dupes_found =[]\n",
    "    \n",
    "    cid_found = {}\n",
    "    #For each list of match at the specific threshold score, we search through the list and identify false positives based\n",
    "    #off of four potential cases.\n",
    "    for j in range(len(matches)):\n",
    "        #Case one: the records are a match and this is the first time we have found this record combination, in which\n",
    "        #song name we decide on which record we are going to consolidate the duplicate names\n",
    "        if (data.iloc[matches[j][0]]['CID'] ==data.iloc[matches[j][1]]['CID']) and (data.iloc[matches[j][0]]['CID'] not in list(cid_found.keys())):\n",
    "            cid_found[data.iloc[matches[j][0]]['CID']] =str(data.iloc[matches[j][1]]['all'])\n",
    "            match_count= match_count+1\n",
    "            dupes_found.append(data.iloc[matches[j][0]]['all'])\n",
    "        #Case two: the records are a match and we already know which record we are standardizing the song to.\n",
    "        elif (data.iloc[matches[j][0]]['CID'] ==data.iloc[matches[j][1]]['CID']) and (cid_found[data.iloc[matches[j][0]]['CID']]==str(data.iloc[matches[j][1]]['all'])) and data.iloc[matches[j][0]]['all'] not in dupes_found:\n",
    "            dupes_found.append(data.iloc[matches[j][0]]['all'])\n",
    "            \n",
    "            match_count=match_count+1\n",
    "        #Case four: False positive\n",
    "        elif  (data.iloc[matches[j][0]]['CID'] !=data.iloc[matches[j][1]]['CID']) and data.iloc[matches[j][0]]['TID'] not in errors_found:\n",
    "            errors_found.append(data.iloc[matches[j][0]]['TID'])\n",
    "            error_count = error_count+1\n",
    "        #All other cases are duplicate match records which can be ignored.\n",
    "        else:\n",
    "            pass\n",
    "    appen_l = [threshold_val, match_count, error_count]\n",
    "    analysis_df = analysis_df.append([appen_l])\n",
    "    print('A threshold value of {} yields {} positives and false positives {}.'.format(threshold_val,match_count, error_count))\n",
    "\n",
    "analysis_df.columns = ['Threshold Value', 'Match Count', 'Error Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the true number of entities and compute the portion that we have found at each score threshold\n",
    "total_true_ents = len(data['CID'].unique())\n",
    "analysis_df['Portion of Duplicates Found']  =  analysis_df['Match Count']/(len(data)-total_true_ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: The Tradeoff Between Score Threshold and Portion of Duplicates Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(analysis_df['Threshold Value'], analysis_df['Match Count'])\n",
    "plt.plot(analysis_df['Threshold Value'], analysis_df['Error Count'])\n",
    "plt.title('Total Positives and False Positives by Threshold of Similarity Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization: Errors Versus Matches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=analysis_df['Error Count'], y=analysis_df['Match Count'], c=analysis_df['Threshold Value'])\n",
    "plt.title('Errors versus Matches in Vectorized Model (Colored by Threshold of Similarity Model)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Finding the Optimum Threshold Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the information that we have in the analysis_df, we can analyze the graphs above to determine the optimum threhold value for our TF-IDF vector.  The way in which you select that value is a more qualitative excercise and depends on your specific use case.  For this illustration, let's take a purely quantative approach and graph the derivative of the plot above.  The derivative will help us determine the optimum number of matches that you can get for the least about of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= {}\n",
    "data['x'] = analysis_df['Match Count'].tolist()\n",
    "data['y'] = analysis_df['Error Count'].tolist()\n",
    "data['y_p'] = np.diff(data['y']) / np.diff(data['x'])\n",
    "data['x_p'] = (np.array(data['x'])[:-1] + np.array(data['x'])[1:]) / 2\n",
    "plt.figure(1)\n",
    "plt.plot(data['x_p'], data['y_p'], 'b')\n",
    "plt.vlines(7618, 0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown at the verticle line in the graph above, it looks like the number of errors per matches increases slowly and then drops before increasing exponentially.  Therefore it seems like the optimum threshold value is just short of 8000 matches.  We can find the exact the exact number of matches at that point by looking at where Y prime drops slightly before taking off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((data['x_p']/data['y_p']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(data['y_p']==.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['x'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df[analysis_df['Match Count']==7618]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, it seems like the optimum threshold value for our entity resolution approach is .58 where we find over 81% of all duplicate records while only making 561 errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
